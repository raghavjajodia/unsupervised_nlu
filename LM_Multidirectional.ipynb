{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pickle as pkl\n",
    "from collections import defaultdict,deque,Counter,OrderedDict\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import lr_scheduler\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "\n",
    "from models import LM_latent, LM_latent_type_rep\n",
    "from vocab import Vocabulary\n",
    "from datasets import POSDataset\n",
    "from utils import pad_list_of_tensors, pad_collate_fn_pos, log_sum_exp\n",
    "from tqdm import tqdm\n",
    "\n",
    "from evaluate import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(9090)\n",
    "cudnn.benchmark = True\n",
    "batch_size = 64\n",
    "    \n",
    "num_gpus = torch.cuda.device_count()\n",
    "if num_gpus > 0:\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_left_to_right = '/misc/vlgscratch4/BrunaGroup/rj1408/nlu/ptb_wsj_pos/models/base_lstm_defpar/a/'\n",
    "\n",
    "#Load forward model\n",
    "forward_model_params = torch.load(os.path.join(model_left_to_right, 'net_epoch_0.pth'), map_location=device)\n",
    "forward_model_weights = torch.load(os.path.join(model_left_to_right, 'net_best_weights.pth'), map_location=device)\n",
    "forward_tag2id = forward_model_params[\"hyperparams\"][\"tagtoid\"]\n",
    "forward_id2tag = defaultdict(str)\n",
    "for tag in forward_tag2id:\n",
    "    forward_id2tag[forward_tag2id[tag]] = tag\n",
    "forward_vocab = forward_model_params[\"hyperparams\"][\"vocab\"]\n",
    "hidden_size = forward_model_params[\"hyperparams\"][\"hidden_size\"]\n",
    "tok_emb_size = forward_model_params[\"hyperparams\"][\"token_embedding\"]\n",
    "tag_emb_size = forward_model_params[\"hyperparams\"][\"tag_emb_size\"]\n",
    "lstm_layers = forward_model_params[\"hyperparams\"][\"lstmLayers\"]\n",
    "dropout_p =  0.1\n",
    "\n",
    "tag_wise_vocabsize = dict([(forward_tag2id[tup[0]], tup[1][2]) for tup in forward_vocab.tag_specific_vocab.items()])\n",
    "forward_model = LM_latent(forward_vocab.vocab_size, tag_wise_vocabsize, hidden_size, tok_emb_size, tag_emb_size, lstm_layers, dropout_p)\n",
    "forward_model.load_state_dict(forward_model_weights)\n",
    "forward_model = forward_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_right_to_left = '/misc/vlgscratch4/BrunaGroup/rj1408/nlu/ptb_wsj_pos/models/base_lstm_defpar_reverse/a/'\n",
    "\n",
    "#Load backward model\n",
    "backward_model_params = torch.load(os.path.join(model_right_to_left, 'net_best_weights.pth'), map_location=device)\n",
    "backward_tag2id = backward_model_params[\"hyperparams\"][\"tagtoid\"]\n",
    "backward_id2tag = defaultdict(str)\n",
    "for tag in backward_tag2id:\n",
    "    backward_id2tag[backward_tag2id[tag]] = tag\n",
    "backward_vocab = backward_model_params[\"hyperparams\"][\"vocab\"]\n",
    "hidden_size = backward_model_params[\"hyperparams\"][\"hidden_size\"]\n",
    "tok_emb_size = backward_model_params[\"hyperparams\"][\"token_embedding\"]\n",
    "tag_emb_size = backward_model_params[\"hyperparams\"][\"tag_emb_size\"]\n",
    "lstm_layers = backward_model_params[\"hyperparams\"][\"lstmLayers\"]\n",
    "dropout_p =  0.1\n",
    "\n",
    "tag_wise_vocabsize = dict([(backward_tag2id[tup[0]], tup[1][2]) for tup in backward_vocab.tag_specific_vocab.items()])\n",
    "backward_model = LM_latent(backward_vocab.vocab_size, tag_wise_vocabsize, hidden_size, tok_emb_size, tag_emb_size, lstm_layers, dropout_p)\n",
    "backward_model.load_state_dict(backward_model_params[\"model_state_dict\"])\n",
    "backward_model = backward_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOR_UNKNOWN_TAG = forward_tag2id['UNKNOWN']\n",
    "BACK_UNKNOWN_TAG = backward_tag2id['UNKNOWN']\n",
    "PAD_TAG_ID = -51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pickle_file = '/misc/vlgscratch4/BrunaGroup/rj1408/nlu/ptb_wsj_pos/val.p'\n",
    "\n",
    "with open(test_pickle_file,\"rb\") as a:\n",
    "    testdict = pkl.load(a)\n",
    "\n",
    "forward_dataset = POSDataset(testdict, forward_vocab, forward_tag2id, forward_id2tag, None, False)\n",
    "backward_dataset = POSDataset(testdict, backward_vocab, backward_tag2id, backward_id2tag, None, True)\n",
    "forward_loader = DataLoader(forward_dataset, batch_size=batch_size, shuffle=False, collate_fn=pad_collate_fn_pos, pin_memory=True)\n",
    "backward_loader = DataLoader(backward_dataset, batch_size=batch_size, shuffle=False, collate_fn=pad_collate_fn_pos, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "backid_to_forid = {}\n",
    "for backid in backward_id2tag:\n",
    "    backtag = backward_id2tag[backid]\n",
    "    forid = forward_tag2id[backtag]\n",
    "    backid_to_forid[backid] = forid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshapeTensor(backward_prob):\n",
    "    ans = torch.zeros(backward_prob.shape, dtype=torch.float, device=device, requires_grad=False)\n",
    "    for j,prob in enumerate(backward_prob):\n",
    "        ans[backid_to_forid[j]] = prob\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertTensTotag(tens, forward = True):\n",
    "    ans = []\n",
    "    for ele in tens:\n",
    "        tagid = ele.item()\n",
    "        if forward:\n",
    "            ans.append(forward_id2tag[tagid])\n",
    "        else:\n",
    "            ans.append(backward_id2tag[tagid])\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTokenAccuracy(for_taglogits, for_labels, back_taglogits, back_labels):\n",
    "    #tag_logits ->  btchsize x sentlen x numtags\n",
    "    #labels -> btchsize x sentlen\n",
    "    btchsize = for_labels.shape[0]\n",
    "    numtags = for_taglogits.shape[2]\n",
    "    \n",
    "    #print(convertTensTotag(for_labels[0], True), convertTensTotag(back_labels[0], False))\n",
    "    \n",
    "    forward_prob = F.softmax(for_taglogits, dim=-1)\n",
    "    backward_prob = F.softmax(back_taglogits, dim =-1)\n",
    "    num = 0\n",
    "    \n",
    "    for i,forlabTens in enumerate(for_labels):\n",
    "        forwardmask = ((forlabTens != PAD_TAG_ID) & (forlabTens != FOR_UNKNOWN_TAG))\n",
    "        paddingRemovedForward = forlabTens[forwardmask]\n",
    "        expandedmask = forwardmask.unsqueeze(-1).expand(for_taglogits[0].shape)\n",
    "        forward_probs_flat = forward_prob[i][expandedmask]\n",
    "        forward_probs = forward_probs_flat.view(-1, numtags)\n",
    "        \n",
    "        backwardmask = ((back_labels[i] != PAD_TAG_ID) & (back_labels[i] != BACK_UNKNOWN_TAG))\n",
    "        paddingRemovedBackward = back_labels[i][backwardmask]\n",
    "        expandedmask = backwardmask.unsqueeze(-1).expand(back_taglogits[0].shape)\n",
    "        backward_probs_flat = backward_prob[i][expandedmask]\n",
    "        backward_probs = backward_probs_flat.view(-1, numtags)\n",
    "        \n",
    "        if paddingRemovedBackward.shape != paddingRemovedForward.shape:\n",
    "            print(paddingRemovedForward.shape, paddingRemovedBackward.shape)\n",
    "            print(convertTensTotag(paddingRemovedForward, True), convertTensTotag(paddingRemovedBackward, False))\n",
    "            print(for_labels.shape, back_labels.shape)\n",
    "        assert paddingRemovedForward.shape == paddingRemovedBackward.shape\n",
    "        \n",
    "        validTokens = paddingRemovedForward.shape[0]\n",
    "        for j in range(validTokens):\n",
    "            lab = paddingRemovedForward[j]\n",
    "            forward_prob_token = forward_probs[j]\n",
    "            backward_prob_token = reshapeTensor(backward_probs[validTokens - j - 1])\n",
    "            final_prob_token = (forward_prob_token + backward_prob_token)/2\n",
    "            num += ((torch.max(final_prob_token, dim=0).indices).item() == lab.item())*1\n",
    "            \n",
    "    mask = ((for_labels != FOR_UNKNOWN_TAG) & (for_labels != PAD_TAG_ID))\n",
    "    den = for_labels[mask].shape[0]\n",
    "\n",
    "    return num, den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentenceAccuracy(for_taglogits, for_labels, back_taglogits, back_labels):\n",
    "    #tag_logits ->  btchsize x sentlen x numtags\n",
    "    #labels -> btchsize x sentlen\n",
    "    btchsize = for_labels.shape[0]\n",
    "    numtags = for_taglogits.shape[2]\n",
    "    \n",
    "    forward_prob = F.softmax(for_taglogits, dim=-1)\n",
    "    backward_prob = F.softmax(back_taglogits, dim =-1)\n",
    "    sentCount = 0\n",
    "    \n",
    "    for i,forlabTens in enumerate(for_labels):\n",
    "        forwardmask = ((forlabTens != PAD_TAG_ID) & (forlabTens != FOR_UNKNOWN_TAG))\n",
    "        paddingRemovedForward = forlabTens[forwardmask]\n",
    "        expandedmask = forwardmask.unsqueeze(-1).expand(for_taglogits[0].shape)\n",
    "        forward_probs_flat = forward_prob[i][expandedmask]\n",
    "        forward_probs = forward_probs_flat.view(-1, numtags)\n",
    "\n",
    "        backwardmask = ((back_labels[i] != PAD_TAG_ID) & (back_labels[i] != BACK_UNKNOWN_TAG))\n",
    "        paddingRemovedBackward = back_labels[i][backwardmask]\n",
    "        expandedmask = backwardmask.unsqueeze(-1).expand(back_taglogits[0].shape)\n",
    "        backward_probs_flat = backward_prob[i][expandedmask]\n",
    "        backward_probs = backward_probs_flat.view(-1, numtags)\n",
    "        \n",
    "        validTokens = paddingRemovedForward.shape[0]\n",
    "        prob_tens_list = []\n",
    "        \n",
    "        for j in range(validTokens):\n",
    "            forward_prob_token = forward_probs[j]\n",
    "            backward_prob_token = reshapeTensor(backward_probs[validTokens - j - 1])\n",
    "            final_prob_token = (forward_prob_token + backward_prob_token)/2\n",
    "            \n",
    "            prob_tens_list.append(final_prob_token)\n",
    "        \n",
    "        predictions = torch.stack(prob_tens_list, dim=0)\n",
    "        predictions = torch.max(predictions, dim=-1).indices\n",
    "        result = torch.equal(predictions, paddingRemovedForward)\n",
    "        sentCount += result*1\n",
    "        \n",
    "    mask = ((for_labels != FOR_UNKNOWN_TAG) & (for_labels != PAD_TAG_ID))\n",
    "    den = for_labels[mask].shape[0]\n",
    "\n",
    "    return sentCount, den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:06,  6.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current acc:  0.5796178343949044\n",
      "current sent acc:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:43,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current acc:  0.5967413441955194\n",
      "current sent acc:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [01:16,  6.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current acc:  0.6086408735366686\n",
      "current sent acc:  5.249619402593312e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [01:46,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current acc:  0.6083345915748151\n",
      "current sent acc:  0.0002264834667069304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [02:18,  6.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current acc:  0.6215887363114897\n",
      "current sent acc:  0.0002027927458137783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [02:52,  6.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current acc:  0.624073642507574\n",
      "current sent acc:  0.0002563505010487066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [03:24,  6.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current acc:  0.6245431322460209\n",
      "current sent acc:  0.00031440361564157986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [03:55,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current acc:  0.6178140282480079\n",
      "current sent acc:  0.00027358845456721727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [04:28,  6.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current acc:  0.616851932197304\n",
      "current sent acc:  0.00023937403689352344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46it [05:00,  6.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current acc:  0.6173336902690403\n",
      "current sent acc:  0.0002409316021951546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [05:33,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current acc:  0.6144979074436945\n",
      "current sent acc:  0.00021772262138036142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56it [06:05,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current acc:  0.6146484891199013\n",
      "current sent acc:  0.00020923266672539864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "61it [06:39,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current acc:  0.6163556309581516\n",
      "current sent acc:  0.00020197123929552432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "66it [07:12,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current acc:  0.6144792588109316\n",
      "current sent acc:  0.0002141626705153871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [07:44,  6.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current acc:  0.6123359853015097\n",
      "current sent acc:  0.000199330941362037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76it [08:16,  6.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current acc:  0.6133946606312818\n",
      "current sent acc:  0.00019468983475700276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [08:48,  6.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current acc:  0.6118890959570988\n",
      "current sent acc:  0.0002053778572243563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "86it [09:23,  7.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current acc:  0.6126982084387824\n",
      "current sent acc:  0.00020017443772430262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "87it [09:25,  5.75s/it]\n"
     ]
    }
   ],
   "source": [
    "forward_model.eval()   # Set model to evaluate mode\n",
    "backward_model.eval()\n",
    "\n",
    "running_word = 0\n",
    "running_sent = 0\n",
    "total_words = 0\n",
    "total_sents = 0\n",
    "n_samples = 0\n",
    "\n",
    "backward_loader = iter(backward_loader)\n",
    "# Iterate over data.\n",
    "for batch_num, (for_inputs, for_targets, for_labels) in tqdm(enumerate(forward_loader)):\n",
    "    \n",
    "    back_inputs, back_targets, back_labels = next(backward_loader)\n",
    "    back_inputs = back_inputs.to(device)\n",
    "    back_targets = back_targets.to(device)\n",
    "    back_labels = back_labels.to(device)\n",
    "    \n",
    "    for_inputs = for_inputs.to(device)\n",
    "    for_targets = for_targets.to(device)\n",
    "    for_labels = for_labels.to(device)\n",
    "    \n",
    "    if for_labels.shape != back_labels.shape:\n",
    "        print(batch_num)\n",
    "        print(for_labels.shape, back_labels.shape)\n",
    "        print(convertTensTotag(for_labels[0], True), convertTensTotag(back_labels[0], False))\n",
    "        print(for_inputs.shape, back_inputs.shape)\n",
    "    assert for_labels.shape == back_labels.shape\n",
    "    \n",
    "    batchSize = for_inputs.size(0)\n",
    "    n_samples += batchSize\n",
    "\n",
    "    for_outputs = forward_model(for_inputs)\n",
    "    back_outputs = backward_model(back_inputs)\n",
    "    \n",
    "    # statistics\n",
    "    num, den = getTokenAccuracy(for_outputs[0], for_labels, back_outputs[0], back_labels)\n",
    "    running_word += num\n",
    "    total_words += den\n",
    "    num, den = getSentenceAccuracy(for_outputs[0], for_labels, back_outputs[0], back_labels)\n",
    "    running_sent += num\n",
    "    total_sents += den\n",
    "    \n",
    "    if batch_num%5==0:\n",
    "        print(\"current acc: \", running_word/total_words)\n",
    "        print(\"current sent acc: \", running_sent/total_sents)\n",
    "\n",
    "# Metrics\n",
    "tokenaccuracy = running_word/total_words\n",
    "sentaccuracy = running_sent/total_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
